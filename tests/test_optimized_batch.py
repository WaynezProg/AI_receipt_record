#!/usr/bin/env python3
"""
æ¸¬è©¦å„ªåŒ–æ‰¹é‡è™•ç†åŠŸèƒ½
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import asyncio
import time
from app.services.optimized_batch_processor import optimized_batch_processor
from app.services.batch_processor import batch_processor

def create_test_images(count: int = 10):
    """å‰µå»ºæ¸¬è©¦åœ–ç‰‡"""
    from PIL import Image, ImageDraw, ImageFont
    import os
    
    # ç¢ºä¿ç›®éŒ„å­˜åœ¨
    os.makedirs("./data/receipts", exist_ok=True)
    
    test_images = []
    for i in range(count):
        # å‰µå»ºæ¸¬è©¦åœ–ç‰‡
        img = Image.new('RGB', (800, 600), color='white')
        draw = ImageDraw.Draw(img)
        
        # æ·»åŠ ä¸€äº›æ–‡å­—
        draw.text((50, 50), f"Test Receipt {i+1}", fill='black')
        draw.text((50, 100), f"Store: Test Store {i+1}", fill='black')
        draw.text((50, 150), f"Date: 2025-01-{i+1:02d}", fill='black')
        draw.text((50, 200), f"Total: Â¥{1000 + i*100}", fill='black')
        
        # ä¿å­˜åœ–ç‰‡
        filename = f"test_receipt_{i+1:03d}.jpg"
        filepath = f"./data/receipts/{filename}"
        img.save(filepath, 'JPEG', quality=85)
        test_images.append(filename)
        
        print(f"âœ… å‰µå»ºæ¸¬è©¦åœ–ç‰‡: {filename}")
    
    return test_images

async def test_optimized_batch_processing():
    """æ¸¬è©¦å„ªåŒ–æ‰¹é‡è™•ç†"""
    print("ğŸ§ª æ¸¬è©¦å„ªåŒ–æ‰¹é‡è™•ç†åŠŸèƒ½")
    print("=" * 60)
    
    # å‰µå»ºæ¸¬è©¦åœ–ç‰‡
    print("ğŸ“ å‰µå»ºæ¸¬è©¦åœ–ç‰‡...")
    test_images = create_test_images(10)
    print(f"âœ… å‰µå»ºäº† {len(test_images)} å€‹æ¸¬è©¦åœ–ç‰‡")
    
    # æ¸¬è©¦æ¨™æº–æ‰¹é‡è™•ç†
    print("\nğŸ”„ æ¸¬è©¦æ¨™æº–æ‰¹é‡è™•ç†...")
    start_time = time.time()
    standard_result = await batch_processor.process_large_batch(test_images, False, True)
    standard_time = time.time() - start_time
    
    print(f"âœ… æ¨™æº–æ‰¹é‡è™•ç†å®Œæˆ:")
    print(f"   æˆåŠŸ: {standard_result['processed_count']}")
    print(f"   å¤±æ•—: {standard_result['failed_count']}")
    print(f"   è€—æ™‚: {standard_time:.2f}ç§’")
    print(f"   å¹³å‡æ¯é …: {standard_time/len(test_images):.2f}ç§’")
    
    # æ¸¬è©¦å„ªåŒ–æ‰¹é‡è™•ç†
    print("\nâš¡ æ¸¬è©¦å„ªåŒ–æ‰¹é‡è™•ç†...")
    start_time = time.time()
    optimized_result = await optimized_batch_processor.process_large_batch_optimized(test_images, True)
    optimized_time = time.time() - start_time
    
    print(f"âœ… å„ªåŒ–æ‰¹é‡è™•ç†å®Œæˆ:")
    print(f"   æˆåŠŸ: {optimized_result['processed_count']}")
    print(f"   å¤±æ•—: {optimized_result['failed_count']}")
    print(f"   è€—æ™‚: {optimized_time:.2f}ç§’")
    print(f"   å¹³å‡æ¯é …: {optimized_time/len(test_images):.2f}ç§’")
    
    # æ€§èƒ½æ¯”è¼ƒ
    print("\nğŸ“Š æ€§èƒ½æ¯”è¼ƒ:")
    if standard_time > 0:
        speedup = standard_time / optimized_time
        print(f"   é€Ÿåº¦æå‡: {speedup:.2f}x")
        print(f"   æ™‚é–“ç¯€çœ: {((standard_time - optimized_time) / standard_time * 100):.1f}%")
    
    # æ¸¬è©¦é€²åº¦è¿½è¹¤
    print("\nğŸ“ˆ æ¸¬è©¦é€²åº¦è¿½è¹¤...")
    standard_progress = batch_processor.get_progress()
    optimized_progress = optimized_batch_processor.get_progress()
    
    print(f"æ¨™æº–é€²åº¦: {standard_progress}")
    print(f"å„ªåŒ–é€²åº¦: {optimized_progress}")
    
    # æ¸…ç†æ¸¬è©¦æª”æ¡ˆ
    print("\nğŸ§¹ æ¸…ç†æ¸¬è©¦æª”æ¡ˆ...")
    for filename in test_images:
        filepath = f"./data/receipts/{filename}"
        if os.path.exists(filepath):
            os.remove(filepath)
            print(f"âœ… åˆªé™¤: {filename}")
    
    print("\nğŸ‰ å„ªåŒ–æ‰¹é‡è™•ç†æ¸¬è©¦å®Œæˆï¼")

async def test_optimization_features():
    """æ¸¬è©¦å„ªåŒ–åŠŸèƒ½ç‰¹æ€§"""
    print("\nğŸ”§ æ¸¬è©¦å„ªåŒ–åŠŸèƒ½ç‰¹æ€§")
    print("=" * 60)
    
    # æ¸¬è©¦ä¸¦è¡Œæ§åˆ¶
    print("ğŸ”„ æ¸¬è©¦ä¸¦è¡Œæ§åˆ¶...")
    print(f"   Azureä¸¦è¡Œæ•¸: {optimized_batch_processor.max_concurrent_azure}")
    print(f"   Claudeä¸¦è¡Œæ•¸: {optimized_batch_processor.max_concurrent_claude}")
    print(f"   æ‰¹æ¬¡å¤§å°: {optimized_batch_processor.batch_size}")
    
    # æ¸¬è©¦å»¶é²æ§åˆ¶
    print("\nâ±ï¸ æ¸¬è©¦å»¶é²æ§åˆ¶...")
    print(f"   Azureå»¶é²: {optimized_batch_processor.azure_delay}ç§’")
    print(f"   Claudeå»¶é²: {optimized_batch_processor.claude_delay}ç§’")
    
    # æ¸¬è©¦å¿«å–æ§åˆ¶
    print("\nğŸ’¾ æ¸¬è©¦å¿«å–æ§åˆ¶...")
    print(f"   ä½¿ç”¨å¿«å–: {optimized_batch_processor.use_cache}")
    print(f"   æœ¬åœ°é è™•ç†: {optimized_batch_processor.use_local_preprocessing}")
    print(f"   è·³éå¢å¼·: {optimized_batch_processor.skip_enhancement}")
    
    # æ¸¬è©¦è‡ªé©æ‡‰å»¶é²
    print("\nğŸ¯ æ¸¬è©¦è‡ªé©æ‡‰å»¶é²...")
    for batch_size in [5, 10, 15, 20]:
        delay = optimized_batch_processor._calculate_adaptive_delay(batch_size)
        print(f"   æ‰¹æ¬¡å¤§å° {batch_size}: {delay:.2f}ç§’å»¶é²")
    
    print("\nâœ… å„ªåŒ–åŠŸèƒ½ç‰¹æ€§æ¸¬è©¦å®Œæˆï¼")

async def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸš€ å„ªåŒ–æ‰¹é‡è™•ç†åŠŸèƒ½æ¸¬è©¦")
    print("=" * 80)
    
    try:
        # æ¸¬è©¦å„ªåŒ–åŠŸèƒ½ç‰¹æ€§
        await test_optimization_features()
        
        # æ¸¬è©¦å¯¦éš›è™•ç†
        await test_optimized_batch_processing()
        
        print("\n" + "=" * 80)
        print("ğŸ‰ æ‰€æœ‰æ¸¬è©¦å®Œæˆï¼")
        print("\nğŸ“‹ å„ªåŒ–åŠŸèƒ½ç¸½çµ:")
        print("âœ… æ™ºèƒ½ä¸¦è¡Œè™•ç†")
        print("âœ… æœ¬åœ°åœ–ç‰‡é è™•ç†")
        print("âœ… å¿«å–æ©Ÿåˆ¶")
        print("âœ… è‡ªé©æ‡‰å»¶é²")
        print("âœ… è·³éåœ–ç‰‡å¢å¼·")
        print("âœ… é‡è©¦æ©Ÿåˆ¶")
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())
