import os
import time
import shutil
from datetime import datetime
from typing import List, Optional
from fastapi import FastAPI, File, UploadFile, HTTPException, BackgroundTasks, Form
from fastapi.responses import FileResponse, JSONResponse, HTMLResponse, Response
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from loguru import logger

from app.config import settings
from app.models.receipt import ReceiptResponse, ReceiptListResponse
from app.services.ocr_service import ocr_service
from app.services.ai_service import ai_service
from app.services.csv_service import csv_service
from app.services.azure_usage_tracker import azure_usage_tracker
from app.services.batch_processor import batch_processor
from app.services.optimized_batch_processor import optimized_batch_processor
from app.services.cache_service import cache_service
from app.utils.image_utils import image_utils

# Configure logging / é…ç½®æ—¥èªŒ
logger.add("logs/app.log", rotation="1 day", retention="7 days", level="INFO")

# Create FastAPI application / å‰µå»ºFastAPIæ‡‰ç”¨
app = FastAPI(
    title="æ—¥æœ¬æ”¶æ“šè­˜åˆ¥ç³»çµ±",
    description="åŸºæ–¼OCR + AIçš„æ—¥æœ¬æ”¶æ“šè­˜åˆ¥å’ŒCSVè¼¸å‡ºç³»çµ±",
    version="1.0.0",
)

# Add CORS middleware / æ·»åŠ CORSä¸­é–“ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Ensure directories exist / ç¢ºä¿ç›®éŒ„å­˜åœ¨
os.makedirs(settings.upload_dir, exist_ok=True)
os.makedirs(settings.output_dir, exist_ok=True)
os.makedirs("logs", exist_ok=True)
os.makedirs("static", exist_ok=True)

# Mount static files / æ›è¼‰éœæ…‹æª”æ¡ˆ
app.mount("/static", StaticFiles(directory="static"), name="static")


@app.get("/", response_class=HTMLResponse)
async def root():
    """
    Root endpoint - Returns web interface
    æ ¹ç«¯é» - è¿”å›Webä»‹é¢
    """
    try:
        with open("static/index.html", "r", encoding="utf-8") as f:
            return HTMLResponse(content=f.read())
    except FileNotFoundError:
        return HTMLResponse(
            content="""
        <html>
        <head><title>æ—¥æœ¬æ”¶æ“šè­˜åˆ¥ç³»çµ±</title></head>
        <body>
            <h1>æ—¥æœ¬æ”¶æ“šè­˜åˆ¥ç³»çµ±</h1>
            <p>è«‹ç¢ºä¿ static/index.html æª”æ¡ˆå­˜åœ¨</p>
            <p><a href="/docs">APIæ–‡æª”</a></p>
        </body>
        </html>
        """
        )


@app.get("/health")
async def health_check():
    """
    Health check endpoint
    å¥åº·æª¢æŸ¥ç«¯é»
    """
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "services": {"ocr": "available", "ai": "available", "csv": "available"},
    }


@app.get("/api-status")
async def check_api_status():
    """
    Check API configuration status
    æª¢æŸ¥ API é…ç½®ç‹€æ…‹

    Returns:
        API configuration status and diagnostic information
        API é…ç½®ç‹€æ…‹å’Œè¨ºæ–·è³‡è¨Š
    """
    status = {
        "azure_vision": {
            "configured": bool(settings.azure_vision_endpoint and settings.azure_vision_key),
            "endpoint": settings.azure_vision_endpoint[:50] + "..." if settings.azure_vision_endpoint and len(settings.azure_vision_endpoint) > 50 else settings.azure_vision_endpoint,
            "endpoint_full": settings.azure_vision_endpoint if settings.azure_vision_endpoint else None,
            "key_set": bool(settings.azure_vision_key),
            "key_preview": settings.azure_vision_key[:10] + "..." if settings.azure_vision_key and len(settings.azure_vision_key) > 10 else None,
            "test_mode": ocr_service.test_mode,
        },
        "claude_api": {
            "configured": bool(settings.claude_api_key),
            "key_set": bool(settings.claude_api_key),
            "key_preview": settings.claude_api_key[:10] + "..." if settings.claude_api_key and len(settings.claude_api_key) > 10 else None,
            "test_mode": ai_service.test_mode,
        },
        "diagnostics": {
            "upload_dir_exists": os.path.exists(settings.upload_dir),
            "output_dir_exists": os.path.exists(settings.output_dir),
        }
    }
    
    # Try to parse Azure endpoint (no actual connection, only format check) / å˜—è©¦è§£æ Azure ç«¯é»ï¼ˆä¸å¯¦éš›é€£æ¥ï¼Œåªæª¢æŸ¥æ ¼å¼ï¼‰
    if settings.azure_vision_endpoint:
        endpoint = settings.azure_vision_endpoint.strip().rstrip("/")
        if not endpoint.startswith("https://"):
            status["azure_vision"]["warning"] = "Endpoint URL should start with https:// / ç«¯é» URL æ‡‰è©²ä»¥ https:// é–‹é ­"
        elif not endpoint.endswith(".cognitiveservices.azure.com"):
            status["azure_vision"]["warning"] = "Endpoint URL format may be incorrect (should include .cognitiveservices.azure.com) / ç«¯é» URL æ ¼å¼å¯èƒ½ä¸æ­£ç¢ºï¼ˆæ‡‰åŒ…å« .cognitiveservices.azure.comï¼‰"
        else:
            status["azure_vision"]["endpoint_valid"] = True
    
    return status


@app.post("/upload", response_model=dict)
async def upload_receipt(file: UploadFile = File(...)):
    """
    Upload receipt image
    ä¸Šå‚³æ”¶æ“šåœ–ç‰‡

    Args:
        file: Uploaded image file / ä¸Šå‚³çš„åœ–ç‰‡æª”æ¡ˆ

    Returns:
        Upload result / ä¸Šå‚³çµæœ
    """
    try:
        # Validate file format / é©—è­‰æª”æ¡ˆæ ¼å¼
        allowed_extensions = settings.allowed_extensions_list
        file_ext = file.filename.split(".")[-1].lower()

        if file_ext not in allowed_extensions:
            raise HTTPException(
                status_code=400,
                detail=f"Unsupported file format. Supported formats: {', '.join(allowed_extensions)} / ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼ã€‚æ”¯æ´çš„æ ¼å¼: {', '.join(allowed_extensions)}",
            )

        # Generate filename (add microseconds to avoid duplicates) / ç”Ÿæˆæª”æ¡ˆåç¨±ï¼ˆæ·»åŠ å¾®ç§’é¿å…é‡è¤‡ï¼‰
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]  # Include milliseconds / åŒ…å«æ¯«ç§’
        filename = f"receipt_{timestamp}.{file_ext}"
        file_path = os.path.join(settings.upload_dir, filename)

        # Save file / å„²å­˜æª”æ¡ˆ
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)

        # Validate image / é©—è­‰åœ–ç‰‡
        if not image_utils.validate_image(file_path, settings.max_file_size):
            os.remove(file_path)  # Delete invalid file / åˆªé™¤ç„¡æ•ˆæª”æ¡ˆ
            raise HTTPException(status_code=400, detail="Invalid image file / ç„¡æ•ˆçš„åœ–ç‰‡æª”æ¡ˆ")

        logger.info(f"Image upload successful: {filename} / åœ–ç‰‡ä¸Šå‚³æˆåŠŸ: {filename}")

        return {
            "success": True,
            "filename": filename,
            "file_path": file_path,
            "file_size": os.path.getsize(file_path),
            "upload_time": datetime.now().isoformat(),
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Image upload failed: {str(e)} / åœ–ç‰‡ä¸Šå‚³å¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Upload failed: {str(e)} / ä¸Šå‚³å¤±æ•—: {str(e)}")


@app.post("/upload-batch")
async def upload_batch_receipts(files: List[UploadFile] = File(...)):
    """
    æ‰¹é‡ä¸Šå‚³æ”¶æ“šåœ–ç‰‡

    Args:
        files: ä¸Šå‚³çš„åœ–ç‰‡æª”æ¡ˆåˆ—è¡¨

    Returns:
        æ‰¹é‡ä¸Šå‚³çµæœ
    """
    try:
        uploaded_files = []
        failed_files = []

        for file_index, file in enumerate(files):
            try:
                # Validate file format / é©—è­‰æª”æ¡ˆæ ¼å¼
                allowed_extensions = settings.allowed_extensions_list
                file_ext = file.filename.split(".")[-1].lower()

                if file_ext not in allowed_extensions:
                    failed_files.append(
                        {
                            "filename": file.filename,
                            "error": f"Unsupported file format. Supported formats: {', '.join(allowed_extensions)} / ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼ã€‚æ”¯æ´çš„æ ¼å¼: {', '.join(allowed_extensions)}",
                        }
                    )
                    continue

                # Generate filename (add index to avoid duplicates) / ç”Ÿæˆæª”æ¡ˆåç¨±ï¼ˆæ·»åŠ ç´¢å¼•é¿å…é‡è¤‡ï¼‰
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"receipt_{timestamp}_{file_index:03d}.{file_ext}"
                file_path = os.path.join(settings.upload_dir, filename)

                # Save file / å„²å­˜æª”æ¡ˆ
                with open(file_path, "wb") as buffer:
                    shutil.copyfileobj(file.file, buffer)
                    buffer.flush()
                    if hasattr(buffer, 'fileno'):
                        try:
                            os.fsync(buffer.fileno())
                        except:
                            pass  # Some systems may not support fsync / æŸäº›ç³»çµ±å¯èƒ½ä¸æ”¯æ´ fsync

                # Verify file exists (wait a short time to ensure file is written) / é©—è­‰æª”æ¡ˆæ˜¯å¦å­˜åœ¨ï¼ˆç­‰å¾…ä¸€å°æ®µæ™‚é–“ç¢ºä¿æª”æ¡ˆå·²å¯«å…¥ï¼‰
                import time
                time.sleep(0.01)  # Brief delay to ensure filesystem sync / çŸ­æš«å»¶é²ç¢ºä¿æª”æ¡ˆç³»çµ±åŒæ­¥
                
                if not os.path.exists(file_path):
                    failed_files.append(
                        {"filename": file.filename, "error": "File save failed / æª”æ¡ˆå„²å­˜å¤±æ•—"}
                    )
                    logger.error(f"File does not exist: {file_path} / æª”æ¡ˆä¸å­˜åœ¨: {file_path}")
                    continue

                # Validate image (PDF files skip image validation) / é©—è­‰åœ–ç‰‡ï¼ˆPDF æª”æ¡ˆè·³éåœ–ç‰‡é©—è­‰ï¼‰
                if file_ext.lower() != "pdf":
                    if not image_utils.validate_image(file_path, settings.max_file_size):
                        if os.path.exists(file_path):
                            os.remove(file_path)  # Delete invalid file / åˆªé™¤ç„¡æ•ˆæª”æ¡ˆ
                        failed_files.append(
                            {"filename": file.filename, "error": "Invalid image file / ç„¡æ•ˆçš„åœ–ç‰‡æª”æ¡ˆ"}
                        )
                        continue

                uploaded_files.append(filename)
                logger.info(f"Batch upload successful: {filename} / æ‰¹é‡ä¸Šå‚³æˆåŠŸ: {filename}")

            except Exception as e:
                failed_files.append({"filename": file.filename, "error": str(e)})
                logger.error(f"æ‰¹é‡ä¸Šå‚³å¤±æ•—: {file.filename}, éŒ¯èª¤: {str(e)}")

        return {
            "success": True,
            "uploaded_count": len(uploaded_files),
            "failed_count": len(failed_files),
            "uploaded_files": uploaded_files,
            "failed_files": failed_files,
            "message": f"æ‰¹é‡ä¸Šå‚³å®Œæˆã€‚æˆåŠŸ: {len(uploaded_files)}, å¤±æ•—: {len(failed_files)}",
        }

    except Exception as e:
        logger.error(f"æ‰¹é‡ä¸Šå‚³å¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡ä¸Šå‚³å¤±æ•—: {str(e)}")


@app.post("/process", response_model=ReceiptResponse)
async def process_receipt(
    filename: str = Form(...),
    background_tasks: BackgroundTasks = BackgroundTasks(),
    enhance_image: bool = Form(True),
    save_detailed_csv: bool = Form(False),
):
    """
    Process receipt recognition
    è™•ç†æ”¶æ“šè­˜åˆ¥

    Args:
        filename: Image file name / åœ–ç‰‡æª”æ¡ˆåç¨±
        background_tasks: Background tasks / èƒŒæ™¯ä»»å‹™
        enhance_image: Whether to enhance image quality / æ˜¯å¦å¢å¼·åœ–ç‰‡å“è³ª
        save_detailed_csv: Whether to save detailed CSV / æ˜¯å¦å„²å­˜è©³ç´°CSV

    Returns:
        Recognition result / è­˜åˆ¥çµæœ
    """
    try:
        start_time = time.time()

        # Build file path / æ§‹å»ºæª”æ¡ˆè·¯å¾‘
        file_path = os.path.join(settings.upload_dir, filename)

        if not os.path.exists(file_path):
            raise HTTPException(status_code=404, detail="File not found / æª”æ¡ˆä¸å­˜åœ¨")

        # åœ–ç‰‡é è™•ç†
        processed_image_path = file_path
        if enhance_image:
            processed_image_path = image_utils.enhance_image_quality(file_path)

        # OCRæ–‡å­—è­˜åˆ¥ï¼ˆæª¢æŸ¥æ˜¯å¦æœ‰æš«å­˜ï¼‰
        logger.info(f"é–‹å§‹OCRè™•ç†: {filename}")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰OCRæš«å­˜
        cache_data = cache_service.load_ocr_result(filename)
        if cache_data and cache_data.get("ocr_data"):
            logger.info(f"ä½¿ç”¨OCRæš«å­˜è³‡æ–™: {filename}")
            ocr_result = cache_data["ocr_data"]
        else:
            # åŸ·è¡ŒOCR
            ocr_result = await ocr_service.extract_text(processed_image_path)
            # ä¿å­˜åˆ°æš«å­˜
            cache_service.save_ocr_result(filename, ocr_result)

        # æå–çµæ§‹åŒ–è³‡æ–™
        structured_data = ocr_service.extract_structured_data(ocr_result)

        # AIæ•´ç†å’Œçµæ§‹åŒ–ï¼ˆæª¢æŸ¥æ˜¯å¦æœ‰æš«å­˜ï¼‰
        logger.info(f"é–‹å§‹AIè™•ç†: {filename}")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰AIæš«å­˜
        ai_cache_data = cache_service.load_ai_result(filename)
        if ai_cache_data and ai_cache_data.get("receipt_data"):
            logger.info(f"ä½¿ç”¨AIæš«å­˜è³‡æ–™: {filename}")
            # å¾æš«å­˜è³‡æ–™æ¢å¾©ReceiptDataå°è±¡
            from app.models.receipt import ReceiptData
            receipt_dict = ai_cache_data["receipt_data"]
            # è™•ç†æ—¥æœŸå­—ä¸²
            if isinstance(receipt_dict.get("date"), str):
                from datetime import datetime
                try:
                    receipt_dict["date"] = datetime.fromisoformat(receipt_dict["date"])
                except:
                    pass
            receipt_data = ReceiptData(**receipt_dict)
        else:
            # åŸ·è¡ŒAIè™•ç†
            receipt_data = await ai_service.process_receipt_text(
                ocr_result, structured_data
            )
            # ä¿å­˜åˆ°æš«å­˜
            cache_service.save_ai_result(filename, receipt_data, ocr_result)

        # è¨­å®šä¾†æºåœ–ç‰‡
        receipt_data.source_image = filename

        # è¨ˆç®—ç¸½è™•ç†æ™‚é–“
        total_time = time.time() - start_time
        receipt_data.processing_time = total_time

        # å„²å­˜CSVæª”æ¡ˆ
        csv_filename = f"receipt_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        csv_path = csv_service.save_receipt_to_csv(receipt_data, csv_filename)

        # å¦‚æœéœ€è¦è©³ç´°CSVï¼Œåœ¨èƒŒæ™¯ä»»å‹™ä¸­è™•ç†
        if save_detailed_csv:
            background_tasks.add_task(
                csv_service.save_detailed_csv, receipt_data, f"detailed_{csv_filename}"
            )

        # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
        if enhance_image and processed_image_path != file_path:
            background_tasks.add_task(os.remove, processed_image_path)

        # è™•ç†æˆåŠŸå¾Œåˆªé™¤åŸå§‹åœ–ç‰‡ï¼ˆèˆ‡æ‰¹é‡è™•ç†ä¿æŒä¸€è‡´ï¼‰
        try:
            if os.path.exists(file_path):
                os.remove(file_path)
                logger.info(f"ğŸ—‘ï¸ å·²åˆªé™¤è™•ç†æˆåŠŸçš„åœ–ç‰‡: {filename}")
        except Exception as e:
            logger.warning(f"åˆªé™¤åœ–ç‰‡å¤±æ•—: {str(e)}")

        logger.info(f"æ”¶æ“šè™•ç†å®Œæˆ: {filename}, è€—æ™‚: {total_time:.2f}ç§’")

        return ReceiptResponse(
            success=True, data=receipt_data, processing_time=total_time
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ”¶æ“šè™•ç†å¤±æ•—: {str(e)}")
        return ReceiptResponse(
            success=False, error=str(e), processing_time=time.time() - start_time
        )


@app.post("/process-batch")
async def process_batch_receipts(
    filenames: List[str] = Form(...),
    background_tasks: BackgroundTasks = BackgroundTasks(),
    enhance_image: bool = Form(True),
    save_detailed_csv: bool = Form(False),
):
    """
    æ‰¹é‡è™•ç†æ”¶æ“šè­˜åˆ¥ï¼ˆåŒ…å«é »ç‡æ§åˆ¶ï¼‰

    Args:
        filenames: åœ–ç‰‡æª”æ¡ˆåç¨±åˆ—è¡¨
        background_tasks: èƒŒæ™¯ä»»å‹™
        enhance_image: æ˜¯å¦å¢å¼·åœ–ç‰‡å“è³ª
        save_detailed_csv: æ˜¯å¦å„²å­˜è©³ç´°CSV

    Returns:
        æ‰¹é‡è™•ç†çµæœ
    """
    try:
        logger.info(f"ğŸ“‹ æ”¶åˆ°æ‰¹é‡è™•ç†è«‹æ±‚:")
        logger.info(f"   æª”æ¡ˆæ•¸é‡: {len(filenames)}")
        logger.info(f"   æª”æ¡ˆåˆ—è¡¨: {filenames}")
        logger.info(f"   å¢å¼·åœ–ç‰‡: {enhance_image}")
        logger.info(f"   å„²å­˜è©³ç´°CSV: {save_detailed_csv}")

        # è©³ç´°æª¢æŸ¥æ¯å€‹æª”æ¡ˆ
        logger.info("ğŸ” è©³ç´°æª”æ¡ˆæª¢æŸ¥:")
        for i, filename in enumerate(filenames):
            file_path = os.path.join(settings.upload_dir, filename)
            exists = os.path.exists(file_path)
            size = os.path.getsize(file_path) if exists else 0
            logger.info(f"   {i+1:2d}. {filename} - å­˜åœ¨: {exists}, å¤§å°: {size} bytes")

        # æª¢æŸ¥æª”æ¡ˆæ•¸é‡
        if len(filenames) > 100:
            logger.warning(f"å¤§é‡æª”æ¡ˆè™•ç†è­¦å‘Š: {len(filenames)} å€‹æª”æ¡ˆ")
            logger.info("å»ºè­°åˆ†æ‰¹è™•ç†å¤§é‡æª”æ¡ˆä»¥é¿å…APIé™åˆ¶")

        # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
        for filename in filenames:
            file_path = os.path.join(settings.upload_dir, filename)
            if not os.path.exists(file_path):
                logger.error(f"æª”æ¡ˆä¸å­˜åœ¨: {file_path}")
                raise HTTPException(status_code=404, detail=f"æª”æ¡ˆä¸å­˜åœ¨: {filename}")
            else:
                logger.info(f"æª”æ¡ˆå­˜åœ¨: {file_path}")

        # ä½¿ç”¨æ‰¹æ¬¡è™•ç†æœå‹™
        result = await batch_processor.process_large_batch(
            filenames, enhance_image, save_detailed_csv
        )

        return result

    except Exception as e:
        logger.error(f"æ‰¹é‡è™•ç†å¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡è™•ç†å¤±æ•—: {str(e)}")


@app.post("/process-batch-optimized")
async def process_batch_optimized(
    filenames: List[str] = Form(...),
    background_tasks: BackgroundTasks = BackgroundTasks(),
    save_detailed_csv: bool = Form(False),
):
    """
    å„ªåŒ–æ‰¹é‡è™•ç†æ”¶æ“šè­˜åˆ¥ï¼ˆå¿«é€Ÿç‰ˆæœ¬ï¼‰

    Args:
        filenames: åœ–ç‰‡æª”æ¡ˆåç¨±åˆ—è¡¨
        background_tasks: èƒŒæ™¯ä»»å‹™
        save_detailed_csv: æ˜¯å¦å„²å­˜è©³ç´°CSV

    Returns:
        å„ªåŒ–æ‰¹é‡è™•ç†çµæœ
    """
    try:
        logger.info(f"ğŸš€ æ”¶åˆ°å„ªåŒ–æ‰¹é‡è™•ç†è«‹æ±‚:")
        logger.info(f"   æª”æ¡ˆæ•¸é‡: {len(filenames)}")
        logger.info(f"   æª”æ¡ˆåˆ—è¡¨: {filenames}")
        logger.info(f"   å„²å­˜è©³ç´°CSV: {save_detailed_csv}")

        # è©³ç´°æª¢æŸ¥æ¯å€‹æª”æ¡ˆ
        logger.info("ğŸ” è©³ç´°æª”æ¡ˆæª¢æŸ¥:")
        for i, filename in enumerate(filenames):
            file_path = os.path.join(settings.upload_dir, filename)
            exists = os.path.exists(file_path)
            size = os.path.getsize(file_path) if exists else 0
            logger.info(f"   {i+1:2d}. {filename} - å­˜åœ¨: {exists}, å¤§å°: {size} bytes")

        # æª¢æŸ¥æª”æ¡ˆæ•¸é‡
        if len(filenames) > 100:
            logger.warning(f"å¤§é‡æª”æ¡ˆè™•ç†è­¦å‘Š: {len(filenames)} å€‹æª”æ¡ˆ")
            logger.info("å„ªåŒ–ç‰ˆæœ¬å¯ä»¥æ›´å¿«é€Ÿåœ°è™•ç†å¤§é‡æª”æ¡ˆ")

        # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
        for filename in filenames:
            file_path = os.path.join(settings.upload_dir, filename)
            if not os.path.exists(file_path):
                logger.error(f"æª”æ¡ˆä¸å­˜åœ¨: {file_path}")
                raise HTTPException(status_code=404, detail=f"æª”æ¡ˆä¸å­˜åœ¨: {filename}")
            else:
                logger.info(f"æª”æ¡ˆå­˜åœ¨: {file_path}")

        # ä½¿ç”¨å„ªåŒ–æ‰¹æ¬¡è™•ç†æœå‹™
        result = await optimized_batch_processor.process_large_batch_optimized(
            filenames, save_detailed_csv
        )

        return result

    except Exception as e:
        logger.error(f"å„ªåŒ–æ‰¹é‡è™•ç†å¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å„ªåŒ–æ‰¹é‡è™•ç†å¤±æ•—: {str(e)}")


@app.post("/ocr-only")
async def process_ocr_only(
    filenames: List[str] = Form(...), enhance_image: bool = Form(True)
):
    """
    åªåŸ·è¡ŒOCRè™•ç†ï¼Œçµæœæš«å­˜
    """
    try:
        logger.info(f"ğŸ“‹ æ”¶åˆ°OCRè™•ç†è«‹æ±‚:")
        logger.info(f"   æª”æ¡ˆæ•¸é‡: {len(filenames)}")
        logger.info(f"   æª”æ¡ˆåˆ—è¡¨: {filenames}")
        logger.info(f"   å¢å¼·åœ–ç‰‡: {enhance_image}")

        # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
        for filename in filenames:
            file_path = os.path.join(settings.upload_dir, filename)
            if not os.path.exists(file_path):
                logger.error(f"æª”æ¡ˆä¸å­˜åœ¨: {file_path}")
                raise HTTPException(status_code=404, detail=f"æª”æ¡ˆä¸å­˜åœ¨: {filename}")
            else:
                logger.info(f"æª”æ¡ˆå­˜åœ¨: {file_path}")

        # åŸ·è¡ŒOCRè™•ç†
        result = await batch_processor.process_ocr_only(filenames, enhance_image)

        return result

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"OCRè™•ç†å¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"OCRè™•ç†å¤±æ•—: {str(e)}")


@app.post("/process-from-cache")
async def process_from_cache(
    batch_id: str = Form(...), save_detailed_csv: bool = Form(True)
):
    """
    å¾æš«å­˜è™•ç†AIåˆ†æ
    """
    try:
        logger.info(f"ğŸ“‹ æ”¶åˆ°å¾æš«å­˜è™•ç†è«‹æ±‚:")
        logger.info(f"   æ‰¹æ¬¡ID: {batch_id}")
        logger.info(f"   å„²å­˜è©³ç´°CSV: {save_detailed_csv}")

        # å¾æš«å­˜è™•ç†AIåˆ†æ
        result = await batch_processor.process_from_cache(batch_id, save_detailed_csv)

        return result

    except Exception as e:
        logger.error(f"å¾æš«å­˜è™•ç†å¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å¾æš«å­˜è™•ç†å¤±æ•—: {str(e)}")


@app.get("/cache-summary")
async def get_cache_summary():
    """
    ç²å–æš«å­˜æ‘˜è¦è³‡è¨Š
    """
    try:
        summary = cache_service.get_cache_summary()
        return summary
    except Exception as e:
        logger.error(f"ç²å–æš«å­˜æ‘˜è¦å¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ç²å–æš«å­˜æ‘˜è¦å¤±æ•—: {str(e)}")


@app.get("/batch-progress")
async def get_batch_progress():
    """
    ç²å–æ‰¹æ¬¡è™•ç†é€²åº¦

    Returns:
        ç•¶å‰æ‰¹æ¬¡è™•ç†é€²åº¦
    """
    try:
        progress = batch_processor.get_progress()

        # æ·»åŠ é »ç‡é™åˆ¶è³‡è¨Š
        usage_summary = azure_usage_tracker.get_usage_summary()

        return {
            "progress": progress,
            "rate_limit_info": {
                "rate_limit": batch_processor.rate_limit,
                "batch_size": batch_processor.batch_size,
                "delay_between_batches": batch_processor.delay_between_batches,
                "delay_between_requests": batch_processor.delay_between_requests,
                "current_hour_usage": usage_summary["current_hour_usage"],
                "warnings": usage_summary["warnings"],
            },
        }

    except Exception as e:
        logger.error(f"ç²å–æ‰¹æ¬¡é€²åº¦å¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ç²å–é€²åº¦å¤±æ•—: {str(e)}")


@app.get("/batch-progress-optimized")
async def get_batch_progress_optimized():
    """
    ç²å–å„ªåŒ–æ‰¹æ¬¡è™•ç†é€²åº¦

    Returns:
        ç•¶å‰å„ªåŒ–æ‰¹æ¬¡è™•ç†é€²åº¦
    """
    try:
        progress = optimized_batch_processor.get_progress()

        # æ·»åŠ å„ªåŒ–è³‡è¨Š
        usage_summary = azure_usage_tracker.get_usage_summary()

        return {
            "progress": progress,
            "optimization_info": {
                "max_concurrent_azure": optimized_batch_processor.max_concurrent_azure,
                "max_concurrent_claude": optimized_batch_processor.max_concurrent_claude,
                "batch_size": optimized_batch_processor.batch_size,
                "azure_delay": optimized_batch_processor.azure_delay,
                "claude_delay": optimized_batch_processor.claude_delay,
                "use_cache": optimized_batch_processor.use_cache,
                "use_local_preprocessing": optimized_batch_processor.use_local_preprocessing,
                "auto_delete_successful": optimized_batch_processor.auto_delete_successful,
                "keep_failed_files": optimized_batch_processor.keep_failed_files,
                "current_hour_usage": usage_summary["current_hour_usage"],
                "warnings": usage_summary["warnings"],
            },
        }

    except Exception as e:
        logger.error(f"ç²å–å„ªåŒ–æ‰¹æ¬¡é€²åº¦å¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ç²å–å„ªåŒ–é€²åº¦å¤±æ•—: {str(e)}")


@app.post("/configure-file-management")
async def configure_file_management(
    auto_delete_successful: bool = Form(True),
    keep_failed_files: bool = Form(True),
    processor_type: str = Form("optimized"),  # "standard" or "optimized"
):
    """
    é…ç½®æª”æ¡ˆç®¡ç†è¨­å®š

    Args:
        auto_delete_successful: è™•ç†æˆåŠŸå¾Œæ˜¯å¦è‡ªå‹•åˆªé™¤åœ–ç‰‡
        keep_failed_files: æ˜¯å¦ä¿ç•™å¤±æ•—çš„æª”æ¡ˆ
        processor_type: è™•ç†å™¨é¡å‹ ("standard" æˆ– "optimized")

    Returns:
        é…ç½®çµæœ
    """
    try:
        if processor_type == "optimized":
            processor = optimized_batch_processor
        else:
            processor = batch_processor

        # æ›´æ–°è¨­å®š
        processor.auto_delete_successful = auto_delete_successful
        processor.keep_failed_files = keep_failed_files

        logger.info(f"æª”æ¡ˆç®¡ç†è¨­å®šå·²æ›´æ–° ({processor_type}):")
        logger.info(f"  è‡ªå‹•åˆªé™¤æˆåŠŸåœ–ç‰‡: {auto_delete_successful}")
        logger.info(f"  ä¿ç•™å¤±æ•—æª”æ¡ˆ: {keep_failed_files}")

        return {
            "success": True,
            "message": "æª”æ¡ˆç®¡ç†è¨­å®šå·²æ›´æ–°",
            "settings": {
                "auto_delete_successful": auto_delete_successful,
                "keep_failed_files": keep_failed_files,
                "processor_type": processor_type,
            },
        }

    except Exception as e:
        logger.error(f"é…ç½®æª”æ¡ˆç®¡ç†è¨­å®šå¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"é…ç½®å¤±æ•—: {str(e)}")


@app.get("/file-management-settings")
async def get_file_management_settings():
    """
    ç²å–æª”æ¡ˆç®¡ç†è¨­å®š

    Returns:
        ç•¶å‰æª”æ¡ˆç®¡ç†è¨­å®š
    """
    try:
        return {
            "standard_processor": {
                "auto_delete_successful": batch_processor.auto_delete_successful,
                "keep_failed_files": batch_processor.keep_failed_files,
            },
            "optimized_processor": {
                "auto_delete_successful": optimized_batch_processor.auto_delete_successful,
                "keep_failed_files": optimized_batch_processor.keep_failed_files,
            },
        }

    except Exception as e:
        logger.error(f"ç²å–æª”æ¡ˆç®¡ç†è¨­å®šå¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ç²å–è¨­å®šå¤±æ•—: {str(e)}")


@app.get("/usage")
async def get_azure_usage():
    """
    ç²å–Azure APIä½¿ç”¨é‡è³‡è¨Š

    Returns:
        Azure APIä½¿ç”¨é‡æ‘˜è¦
    """
    try:
        usage_summary = azure_usage_tracker.get_usage_summary()
        daily_chart = azure_usage_tracker.get_daily_usage_chart()
        recent_calls = azure_usage_tracker.get_recent_api_calls()

        return {
            "summary": usage_summary,
            "daily_chart": daily_chart,
            "recent_calls": recent_calls,
            "limits": {
                "monthly_limit": 5000,
                "rate_limit_per_minute": 20,
                "max_image_size_mb": 4,
                "supported_formats": ["JPEG", "PNG", "GIF", "BMP"],
            },
            "cost_info": {
                "free_tier": "å‰5000æ¬¡äº¤æ˜“å…è²»",
                "paid_tier": "$1.00 per 1000 transactions",
                "estimated_cost": usage_summary["total_cost_estimate"],
            },
        }

    except Exception as e:
        logger.error(f"ç²å–Azureä½¿ç”¨é‡å¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ç²å–ä½¿ç”¨é‡å¤±æ•—: {str(e)}")


@app.get("/download/{filename}")
async def download_file(filename: str):
    """
    ä¸‹è¼‰CSVæª”æ¡ˆ

    Args:
        filename: æª”æ¡ˆåç¨±

    Returns:
        æª”æ¡ˆå…§å®¹
    """
    try:
        file_path = os.path.join(settings.output_dir, filename)

        if not os.path.exists(file_path):
            raise HTTPException(status_code=404, detail="æª”æ¡ˆä¸å­˜åœ¨")

        # è®€å–æª”æ¡ˆå…§å®¹
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()

        # è¨­å®šå›æ‡‰æ¨™é ­
        headers = {
            "Content-Disposition": f"attachment; filename={filename}",
            "Content-Type": "text/csv; charset=utf-8",
        }

        return Response(content=content, headers=headers)

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ä¸‹è¼‰æª”æ¡ˆå¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ä¸‹è¼‰æª”æ¡ˆå¤±æ•—: {str(e)}")


@app.get("/uploaded-files")
async def get_uploaded_files():
    """
    ç²å–æ‰€æœ‰å·²ä¸Šå‚³çš„åœ–ç‰‡æª”æ¡ˆåˆ—è¡¨ï¼ˆåŒ…å«è™•ç†ç‹€æ…‹ï¼‰

    Returns:
        å·²ä¸Šå‚³çš„æª”æ¡ˆåˆ—è¡¨ï¼ˆåŒ…å«æª”åã€å¤§å°ã€ä¸Šå‚³æ™‚é–“ã€åœ–ç‰‡URLã€è™•ç†ç‹€æ…‹ï¼‰
    """
    try:
        files = []
        allowed_extensions = (".jpg", ".jpeg", ".png", ".pdf")
        
        if os.path.exists(settings.upload_dir):
            for filename in os.listdir(settings.upload_dir):
                # åªé¡¯ç¤ºåœ–ç‰‡æª”æ¡ˆï¼Œæ’é™¤è™•ç†éçš„æª”æ¡ˆï¼ˆå¦‚ _resized, _enhanced ç­‰ï¼‰
                if any(filename.lower().endswith(ext) for ext in allowed_extensions):
                    file_path = os.path.join(settings.upload_dir, filename)
                    
                    # è·³éè™•ç†éçš„æª”æ¡ˆï¼ˆåŒ…å« _resized, _enhanced ç­‰å¾Œç¶´ï¼‰
                    if any(suffix in filename for suffix in ["_resized", "_enhanced"]):
                        continue
                    
                    try:
                        file_stat = os.stat(file_path)
                        
                        # æª¢æŸ¥è™•ç†ç‹€æ…‹
                        processing_status = "not_processed"  # æœªè™•ç†
                        has_ocr_cache = False
                        
                        # æª¢æŸ¥æ˜¯å¦æœ‰OCRæš«å­˜
                        cache_data = cache_service.load_ocr_result(filename)
                        if cache_data:
                            has_ocr_cache = True
                            processing_status = "ocr_completed"  # OCRå·²å®Œæˆ
                        
                        # æª¢æŸ¥æ˜¯å¦å·²æœ‰CSVè¼¸å‡ºï¼ˆè¡¨ç¤ºå·²å®Œæˆè™•ç†ï¼‰
                        csv_files = []
                        if os.path.exists(settings.output_dir):
                            csv_files = [f for f in os.listdir(settings.output_dir) 
                                       if f.endswith(".csv") and not f.startswith("detailed_")]
                        
                        # ç°¡å–®æª¢æŸ¥ï¼šå¦‚æœCSVæª”æ¡ˆè¼ƒæ–°æ–¼ä¸Šå‚³æ™‚é–“ï¼Œå¯èƒ½å·²è™•ç†ï¼ˆé€™åªæ˜¯ç²—ç•¥åˆ¤æ–·ï¼‰
                        # æ›´æº–ç¢ºçš„æ–¹æ³•éœ€è¦æª¢æŸ¥CSVå…§å®¹ï¼Œä½†é€™è£¡å…ˆç°¡å–®åˆ¤æ–·
                        
                        files.append({
                            "filename": filename,
                            "size": file_stat.st_size,
                            "size_mb": round(file_stat.st_size / (1024 * 1024), 2),
                            "upload_time": datetime.fromtimestamp(file_stat.st_mtime).isoformat(),
                            "modified_time": datetime.fromtimestamp(file_stat.st_mtime).strftime("%Y-%m-%d %H:%M:%S"),
                            "image_url": f"/receipt-image/{filename}",
                            "processing_status": processing_status,
                            "has_ocr_cache": has_ocr_cache,
                        })
                    except Exception as e:
                        logger.warning(f"è®€å–æª”æ¡ˆè³‡è¨Šå¤±æ•—: {filename}, éŒ¯èª¤: {str(e)}")
                        continue
        
        # æŒ‰ä¿®æ”¹æ™‚é–“æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        files.sort(key=lambda x: x["upload_time"], reverse=True)
        
        return {
            "success": True,
            "files": files,
            "total_count": len(files),
        }
    
    except Exception as e:
        logger.error(f"ç²å–ä¸Šå‚³æª”æ¡ˆåˆ—è¡¨å¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ç²å–æª”æ¡ˆåˆ—è¡¨å¤±æ•—: {str(e)}")


@app.get("/file-status/{filename}")
async def get_file_status(filename: str):
    """
    æª¢æŸ¥æª”æ¡ˆçš„è™•ç†ç‹€æ…‹

    Args:
        filename: æª”æ¡ˆåç¨±

    Returns:
        æª”æ¡ˆçš„è™•ç†ç‹€æ…‹ï¼ˆæ˜¯å¦å·²ä¸Šå‚³ã€æ˜¯å¦æœ‰OCRæš«å­˜ã€æ˜¯å¦å¯ä»¥è™•ç†ï¼‰
    """
    try:
        # å®‰å…¨æª¢æŸ¥ï¼šé˜²æ­¢è·¯å¾‘éæ­·æ”»æ“Š
        if ".." in filename or "/" in filename:
            raise HTTPException(status_code=400, detail="ç„¡æ•ˆçš„æª”æ¡ˆåç¨±")
        
        file_path = os.path.join(settings.upload_dir, filename)
        
        result = {
            "filename": filename,
            "exists": os.path.exists(file_path),
            "has_ocr_cache": False,
            "processing_status": "not_processed",
            "can_process": False,
        }
        
        if not result["exists"]:
            return result
        
        # æª¢æŸ¥OCRæš«å­˜
        cache_data = cache_service.load_ocr_result(filename)
        if cache_data:
            result["has_ocr_cache"] = True
            result["processing_status"] = "ocr_completed"
            result["can_process"] = True  # æœ‰OCRæš«å­˜ï¼Œå¯ä»¥ç›´æ¥è™•ç†
        
        # å¦‚æœæª”æ¡ˆå­˜åœ¨ï¼Œä¹Ÿå¯ä»¥è™•ç†ï¼ˆå³ä½¿æ²’æœ‰æš«å­˜ï¼‰
        if not result["can_process"]:
            result["can_process"] = True
            result["processing_status"] = "not_processed"
        
        return result
    
    except Exception as e:
        logger.error(f"æª¢æŸ¥æª”æ¡ˆç‹€æ…‹å¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æª¢æŸ¥æª”æ¡ˆç‹€æ…‹å¤±æ•—: {str(e)}")


@app.get("/receipt-image/{filename}")
async def get_receipt_image(filename: str):
    """
    ç²å–ä¸Šå‚³çš„æ”¶æ“šåœ–ç‰‡

    Args:
        filename: åœ–ç‰‡æª”æ¡ˆåç¨±

    Returns:
        åœ–ç‰‡æª”æ¡ˆ
    """
    try:
        # å®‰å…¨æª¢æŸ¥ï¼šé˜²æ­¢è·¯å¾‘éæ­·æ”»æ“Š
        if ".." in filename or "/" in filename:
            raise HTTPException(status_code=400, detail="ç„¡æ•ˆçš„æª”æ¡ˆåç¨±")
        
        file_path = os.path.join(settings.upload_dir, filename)
        
        if not os.path.exists(file_path):
            raise HTTPException(status_code=404, detail="åœ–ç‰‡ä¸å­˜åœ¨")
        
        # æ ¹æ“šæª”æ¡ˆæ“´å±•åæ±ºå®š MIME é¡å‹
        ext = filename.split(".")[-1].lower()
        media_types = {
            "jpg": "image/jpeg",
            "jpeg": "image/jpeg",
            "png": "image/png",
            "pdf": "application/pdf",
        }
        media_type = media_types.get(ext, "application/octet-stream")
        
        return FileResponse(file_path, media_type=media_type, filename=filename)
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ç²å–åœ–ç‰‡å¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ç²å–åœ–ç‰‡å¤±æ•—: {str(e)}")


@app.get("/receipts", response_model=ReceiptListResponse)
async def get_receipts(limit: int = 10, offset: int = 0):
    """
    ç²å–å·²è™•ç†çš„æ”¶æ“šåˆ—è¡¨

    Args:
        limit: é™åˆ¶æ•¸é‡
        offset: åç§»é‡

    Returns:
        æ”¶æ“šåˆ—è¡¨
    """
    try:
        # æƒæè¼¸å‡ºç›®éŒ„ä¸­çš„CSVæª”æ¡ˆ
        csv_files = []
        for file in os.listdir(settings.output_dir):
            if file.endswith(".csv") and not file.startswith("detailed_"):
                csv_files.append(file)

        # æŒ‰æ™‚é–“æ’åº
        csv_files.sort(reverse=True)

        # åˆ†é 
        csv_files = csv_files[offset : offset + limit]

        # è¼‰å…¥æ”¶æ“šè³‡æ–™
        receipts = []
        for csv_file in csv_files:
            try:
                csv_path = os.path.join(settings.output_dir, csv_file)
                file_receipts = csv_service.load_receipts_from_csv(csv_path)
                receipts.extend(file_receipts)
            except Exception as e:
                logger.warning(f"è¼‰å…¥CSVæª”æ¡ˆå¤±æ•—: {csv_file}, éŒ¯èª¤: {str(e)}")
                continue

        return ReceiptListResponse(receipts=receipts, total_count=len(receipts))

    except Exception as e:
        logger.error(f"ç²å–æ”¶æ“šåˆ—è¡¨å¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ç²å–æ”¶æ“šåˆ—è¡¨å¤±æ•—: {str(e)}")


@app.get("/download/{filename}")
async def download_csv(filename: str):
    """
    ä¸‹è¼‰CSVæª”æ¡ˆ

    Args:
        filename: CSVæª”æ¡ˆåç¨±

    Returns:
        CSVæª”æ¡ˆ
    """
    try:
        file_path = os.path.join(settings.output_dir, filename)

        if not os.path.exists(file_path):
            raise HTTPException(status_code=404, detail="æª”æ¡ˆä¸å­˜åœ¨")

        return FileResponse(file_path, media_type="text/csv", filename=filename)

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ä¸‹è¼‰CSVæª”æ¡ˆå¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ä¸‹è¼‰å¤±æ•—: {str(e)}")


@app.get("/csv-files-list")
async def get_csv_files_list():
    """
    ç²å–æ‰€æœ‰å¯ç”¨çš„CSVæª”æ¡ˆåˆ—è¡¨

    Returns:
        CSVæª”æ¡ˆåˆ—è¡¨
    """
    try:
        if not os.path.exists(settings.output_dir):
            return {
                "success": False,
                "message": "è¼¸å‡ºç›®éŒ„ä¸å­˜åœ¨",
                "csv_files": []
            }

        # æŸ¥æ‰¾æ‰€æœ‰summary CSVæª”æ¡ˆ
        csv_files_list = [
            f
            for f in os.listdir(settings.output_dir)
            if f.startswith("receipts_summary_") and f.endswith(".csv")
        ]

        csv_files_list.sort(reverse=True)  # æœ€æ–°çš„åœ¨å‰

        # æ ¼å¼åŒ–æª”æ¡ˆåç¨±ç‚ºé¡¯ç¤ºåç¨±ï¼ˆæå–æ™‚é–“æˆ³ï¼‰
        csv_files_with_info = []
        for csv_file in csv_files_list:
            # receipts_summary_20251230_164641.csv -> 2025-12-30 16:46:41
            try:
                timestamp_str = csv_file.replace("receipts_summary_", "").replace(".csv", "")
                date_str = timestamp_str[:8]  # 20251230
                time_str = timestamp_str[9:]  # 164641
                formatted_date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]} {time_str[:2]}:{time_str[2:4]}:{time_str[4:6]}"
                csv_files_with_info.append({
                    "filename": csv_file,
                    "display_name": formatted_date
                })
            except:
                csv_files_with_info.append({
                    "filename": csv_file,
                    "display_name": csv_file
                })

        return {
            "success": True,
            "csv_files": csv_files_with_info
        }

    except Exception as e:
        logger.error(f"ç²å–CSVæª”æ¡ˆåˆ—è¡¨å¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ç²å–CSVæª”æ¡ˆåˆ—è¡¨å¤±æ•—: {str(e)}")


@app.get("/csv-data/{filename}")
async def get_csv_data(filename: str):
    """
    ç²å–æŒ‡å®šCSVæª”æ¡ˆçš„å®Œæ•´è³‡æ–™ï¼ˆåŒ…å«æ‘˜è¦å’Œæ˜ç´°ï¼‰
    ä¸¦è‡ªå‹•åˆªé™¤å·²è™•ç†çš„åœ–ç‰‡ï¼ˆåƒ…é™æœ€æ–°æª”æ¡ˆï¼‰

    Args:
        filename: CSVæª”æ¡ˆåç¨±ï¼ˆreceipts_summary_*.csvï¼‰

    Returns:
        CSVè³‡æ–™ï¼ˆæ‘˜è¦å’Œæ˜ç´°ï¼‰
    """
    try:
        import csv
        
        if not os.path.exists(settings.output_dir):
            return {
                "success": False,
                "message": "è¼¸å‡ºç›®éŒ„ä¸å­˜åœ¨",
                "summary_data": [],
                "details_data": []
            }

        # é©—è­‰æª”æ¡ˆåç¨±
        if not filename.startswith("receipts_summary_") or not filename.endswith(".csv"):
            raise HTTPException(status_code=400, detail="ç„¡æ•ˆçš„CSVæª”æ¡ˆåç¨±")

        summary_path = os.path.join(settings.output_dir, filename)
        if not os.path.exists(summary_path):
            raise HTTPException(status_code=404, detail="CSVæª”æ¡ˆä¸å­˜åœ¨")
        
        # æ¨æ–·å°æ‡‰çš„details CSVæª”æ¡ˆåç¨±
        timestamp = filename.replace("receipts_summary_", "").replace(".csv", "")
        details_filename = f"receipts_details_{timestamp}.csv"
        details_path = os.path.join(settings.output_dir, details_filename)
        
        # è®€å–summary CSV
        summary_data = []
        processed_images = set()  # æ”¶é›†æ‰€æœ‰å·²è™•ç†çš„åœ–ç‰‡æª”å
        if os.path.exists(summary_path):
            with open(summary_path, "r", encoding="utf-8") as f:
                reader = csv.DictReader(f)
                summary_data = list(reader)
                # å¾summary CSVä¸­æå–å·²è™•ç†çš„åœ–ç‰‡æª”å
                for row in summary_data:
                    source_image = row.get("ä¾†æºåœ–ç‰‡", "").strip()
                    if source_image:
                        processed_images.add(source_image)
        
        # è®€å–details CSV
        details_data = []
        if os.path.exists(details_path):
            with open(details_path, "r", encoding="utf-8") as f:
                reader = csv.DictReader(f)
                details_data = list(reader)
        
        # åªæœ‰åœ¨è«‹æ±‚æœ€æ–°æª”æ¡ˆæ™‚æ‰åˆªé™¤å·²è™•ç†çš„åœ–ç‰‡
        deleted_count = 0
        csv_files_list = [
            f
            for f in os.listdir(settings.output_dir)
            if f.startswith("receipts_summary_") and f.endswith(".csv")
        ]
        if csv_files_list:
            csv_files_list.sort(reverse=True)
            is_latest = csv_files_list[0] == filename
            
            if is_latest and processed_images and os.path.exists(settings.upload_dir):
                for image_filename in processed_images:
                    image_path = os.path.join(settings.upload_dir, image_filename)
                    if os.path.exists(image_path):
                        try:
                            os.remove(image_path)
                            logger.info(f"ğŸ—‘ï¸ å·²åˆªé™¤CSVä¸­å·²è¨˜éŒ„çš„åœ–ç‰‡: {image_filename}")
                            deleted_count += 1
                        except Exception as e:
                            logger.warning(f"åˆªé™¤åœ–ç‰‡å¤±æ•— {image_filename}: {str(e)}")
                
                if deleted_count > 0:
                    logger.info(f"âœ… å·²æ¸…ç† {deleted_count} å€‹å·²è™•ç†çš„åœ–ç‰‡æª”æ¡ˆ")
        
        return {
            "success": True,
            "summary_filename": filename,
            "details_filename": details_filename,
            "summary_data": summary_data,
            "details_data": details_data,
            "deleted_images_count": deleted_count,
            "is_latest": csv_files_list and csv_files_list[0] == filename if csv_files_list else False
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è®€å–CSVè³‡æ–™å¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è®€å–CSVè³‡æ–™å¤±æ•—: {str(e)}")


@app.get("/latest-csv-data")
async def get_latest_csv_data():
    """
    ç²å–æœ€æ–°CSVæª”æ¡ˆçš„å®Œæ•´è³‡æ–™ï¼ˆåŒ…å«æ‘˜è¦å’Œæ˜ç´°ï¼‰
    ä¸¦è‡ªå‹•åˆªé™¤å·²è™•ç†çš„åœ–ç‰‡

    Returns:
        CSVè³‡æ–™ï¼ˆæ‘˜è¦å’Œæ˜ç´°ï¼‰
    """
    try:
        if not os.path.exists(settings.output_dir):
            return {
                "success": False,
                "message": "è¼¸å‡ºç›®éŒ„ä¸å­˜åœ¨",
                "summary_data": [],
                "details_data": []
            }

        # æŸ¥æ‰¾æœ€æ–°çš„summary CSVæª”æ¡ˆ
        csv_files_list = [
            f
            for f in os.listdir(settings.output_dir)
            if f.startswith("receipts_summary_") and f.endswith(".csv")
        ]

        if not csv_files_list:
            return {
                "success": False,
                "message": "æ²’æœ‰æ‰¾åˆ°CSVæª”æ¡ˆ",
                "summary_data": [],
                "details_data": []
            }

        csv_files_list.sort(reverse=True)
        latest_summary_csv = csv_files_list[0]
        
        # ä½¿ç”¨æ–°çš„ç«¯é»ä¾†ç²å–è³‡æ–™ï¼ˆé€šéå…§éƒ¨èª¿ç”¨ï¼‰
        # é€™è£¡éœ€è¦é‡æ–°å¯¦ç¾é‚è¼¯ï¼Œå› ç‚ºä¸èƒ½ç›´æ¥èª¿ç”¨å¦ä¸€å€‹è·¯ç”±è™•ç†å‡½æ•¸
        import csv
        
        summary_path = os.path.join(settings.output_dir, latest_summary_csv)
        
        # æ¨æ–·å°æ‡‰çš„details CSVæª”æ¡ˆåç¨±
        timestamp = latest_summary_csv.replace("receipts_summary_", "").replace(".csv", "")
        details_filename = f"receipts_details_{timestamp}.csv"
        details_path = os.path.join(settings.output_dir, details_filename)
        
        # è®€å–summary CSV
        summary_data = []
        processed_images = set()
        if os.path.exists(summary_path):
            with open(summary_path, "r", encoding="utf-8") as f:
                reader = csv.DictReader(f)
                summary_data = list(reader)
                for row in summary_data:
                    source_image = row.get("ä¾†æºåœ–ç‰‡", "").strip()
                    if source_image:
                        processed_images.add(source_image)
        
        # è®€å–details CSV
        details_data = []
        if os.path.exists(details_path):
            with open(details_path, "r", encoding="utf-8") as f:
                reader = csv.DictReader(f)
                details_data = list(reader)
        
        # åˆªé™¤å·²è™•ç†çš„åœ–ç‰‡ï¼ˆåƒ…é™æœ€æ–°æª”æ¡ˆï¼‰
        deleted_count = 0
        if processed_images and os.path.exists(settings.upload_dir):
            for image_filename in processed_images:
                image_path = os.path.join(settings.upload_dir, image_filename)
                if os.path.exists(image_path):
                    try:
                        os.remove(image_path)
                        logger.info(f"ğŸ—‘ï¸ å·²åˆªé™¤CSVä¸­å·²è¨˜éŒ„çš„åœ–ç‰‡: {image_filename}")
                        deleted_count += 1
                    except Exception as e:
                        logger.warning(f"åˆªé™¤åœ–ç‰‡å¤±æ•— {image_filename}: {str(e)}")
        
        if deleted_count > 0:
            logger.info(f"âœ… å·²æ¸…ç† {deleted_count} å€‹å·²è™•ç†çš„åœ–ç‰‡æª”æ¡ˆ")
        
        return {
            "success": True,
            "summary_filename": latest_summary_csv,
            "details_filename": details_filename,
            "summary_data": summary_data,
            "details_data": details_data,
            "deleted_images_count": deleted_count,
            "is_latest": True
        }

    except Exception as e:
        logger.error(f"è®€å–CSVè³‡æ–™å¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è®€å–CSVè³‡æ–™å¤±æ•—: {str(e)}")


@app.get("/summary")
async def get_summary():
    """
    ç²å–ç³»çµ±æ‘˜è¦è³‡è¨Š

    Returns:
        æ‘˜è¦è³‡è¨Š
    """
    try:
        # çµ±è¨ˆæª”æ¡ˆæ•¸é‡ï¼ˆç¢ºä¿ç›®éŒ„å­˜åœ¨ï¼‰
        receipt_files = 0
        if os.path.exists(settings.upload_dir):
            receipt_files = len(
                [
                    f
                    for f in os.listdir(settings.upload_dir)
                    if f.lower().endswith((".jpg", ".jpeg", ".png"))
                ]
            )
        
        csv_files = 0
        if os.path.exists(settings.output_dir):
            csv_files = len(
                [f for f in os.listdir(settings.output_dir) if f.endswith(".csv")]
            )

        # ç²å–æœ€æ–°çš„CSVæ‘˜è¦
        latest_csv = None
        csv_summary = None

        csv_files_list = []
        if os.path.exists(settings.output_dir):
            csv_files_list = [
                f
                for f in os.listdir(settings.output_dir)
                if f.endswith(".csv") and not f.startswith("detailed_")
            ]

        if csv_files_list:
            csv_files_list.sort(reverse=True)
            latest_csv = csv_files_list[0]
            csv_path = os.path.join(settings.output_dir, latest_csv)
            csv_summary = csv_service.get_csv_summary(csv_path)

        return {
            "uploaded_receipts": receipt_files,
            "processed_csv_files": csv_files,
            "latest_csv": latest_csv,
            "csv_summary": csv_summary,
            "system_status": "running",
            "last_updated": datetime.now().isoformat(),
        }

    except Exception as e:
        logger.error(f"ç²å–æ‘˜è¦è³‡è¨Šå¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ç²å–æ‘˜è¦å¤±æ•—: {str(e)}")


@app.delete("/uploaded-image/{filename}")
async def delete_uploaded_image(filename: str):
    """
    åˆªé™¤å·²ä¸Šå‚³çš„åœ–ç‰‡æª”æ¡ˆï¼ˆåƒ…åˆªé™¤åœ–ç‰‡ï¼Œä¸åˆªé™¤CSVï¼‰

    Args:
        filename: åœ–ç‰‡æª”æ¡ˆåç¨±

    Returns:
        åˆªé™¤çµæœ
    """
    try:
        # åˆªé™¤ä¸Šå‚³çš„åœ–ç‰‡
        image_path = os.path.join(settings.upload_dir, filename)
        
        if not os.path.exists(image_path):
            raise HTTPException(status_code=404, detail="åœ–ç‰‡æª”æ¡ˆä¸å­˜åœ¨")

        os.remove(image_path)
        logger.info(f"ğŸ—‘ï¸ å·²åˆªé™¤åœ–ç‰‡: {filename}")

        # åŒæ™‚åˆªé™¤ç›¸é—œçš„æš«å­˜æª”æ¡ˆï¼ˆOCRå’ŒAIæš«å­˜ï¼‰
        try:
            from app.services.cache_service import cache_service
            cache_service.delete_ocr_cache(filename)
            cache_service.delete_ai_cache(filename)
        except Exception as e:
            logger.warning(f"åˆªé™¤æš«å­˜æª”æ¡ˆå¤±æ•—: {str(e)}")

        return {
            "success": True,
            "deleted_image": filename,
            "message": f"å·²åˆªé™¤åœ–ç‰‡: {filename}"
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åˆªé™¤åœ–ç‰‡å¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆªé™¤å¤±æ•—: {str(e)}")


@app.delete("/receipts/{filename}")
async def delete_receipt(filename: str):
    """
    åˆªé™¤æ”¶æ“šæª”æ¡ˆï¼ˆåŒ…å«åœ–ç‰‡å’ŒCSVï¼‰

    Args:
        filename: æª”æ¡ˆåç¨±

    Returns:
        åˆªé™¤çµæœ
    """
    try:
        # åˆªé™¤ä¸Šå‚³çš„åœ–ç‰‡
        image_path = os.path.join(settings.upload_dir, filename)
        if os.path.exists(image_path):
            os.remove(image_path)

        # åˆªé™¤ç›¸é—œçš„CSVæª”æ¡ˆ
        base_name = os.path.splitext(filename)[0]
        csv_patterns = [
            f"receipt_*{base_name}*.csv",
            f"detailed_receipt_*{base_name}*.csv",
        ]

        deleted_files = []
        for pattern in csv_patterns:
            for file in os.listdir(settings.output_dir):
                if file.endswith(".csv") and base_name in file:
                    csv_path = os.path.join(settings.output_dir, file)
                    os.remove(csv_path)
                    deleted_files.append(file)

        logger.info(f"åˆªé™¤æ”¶æ“šæª”æ¡ˆ: {filename}, åŒæ™‚åˆªé™¤CSVæª”æ¡ˆ: {deleted_files}")

        return {
            "success": True,
            "deleted_image": filename,
            "deleted_csv_files": deleted_files,
        }

    except Exception as e:
        logger.error(f"åˆªé™¤æ”¶æ“šæª”æ¡ˆå¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆªé™¤å¤±æ•—: {str(e)}")


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8000)
